{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from data import DataPreprocessor\n",
    "from utils import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.encodings = tokenizer(texts, truncation=True, padding=True, max_length=max_length)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        # Assicurati che le etichette siano interi e non one-hot, e sono scalari per ogni esempio.\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)  # dtype=torch.long per etichette di classificazione\n",
    "        return item\n",
    "\n",
    "class DistilBertModelBuilder:\n",
    "    def __init__(self, num_labels, max_length=512):\n",
    "        # Il tokenizer Ã¨ definito come attributo della classe qui\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "        self.model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=num_labels)\n",
    "        self.max_length = max_length\n",
    "        self.trainer = None\n",
    "\n",
    "    def train(self, X_train, y_train, X_val, y_val, epochs=3, batch_size=8):\n",
    "        # Utilizzo del tokenizer definito nell'oggetto\n",
    "        train_dataset = SentimentDataset(X_train, y_train, self.tokenizer, self.max_length)\n",
    "        val_dataset = SentimentDataset(X_val, y_val, self.tokenizer, self.max_length)\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./results',\n",
    "            num_train_epochs=epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            warmup_steps=500,\n",
    "            weight_decay=0.01,\n",
    "            logging_dir='./logs',\n",
    "            logging_steps=10,\n",
    "        )\n",
    "\n",
    "        self.trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset\n",
    "        )\n",
    "\n",
    "        self.trainer.train()\n",
    "\n",
    "    def predict(self, X_test, y_test):\n",
    "        test_dataset = SentimentDataset(X_test, y_test, self.tokenizer, self.max_length)\n",
    "        predictions = self.trainer.predict(test_dataset)\n",
    "        print(f\"Predictions shape: {predictions.predictions.shape}\")  # Dimensioni dell'output del modello\n",
    "        print(f\"Label shape: {predictions.label_ids.shape}\")  # Dimensioni delle etichette\n",
    "        y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        print(f'F1 score: {f1:.2f}')\n",
    "        print(f'Accuracy: {accuracy:.2f}')\n",
    "        print(classification_report(y_test, y_pred)) \n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load, preprocess and split balanced data\n",
    "preprocessor = DataPreprocessor('balanced_train_data.csv')\n",
    "preprocessor.load_and_preprocess()\n",
    "preprocessor.split_data()\n",
    "#preprocessor.oversample()\n",
    "X_train_balanced, X_val_balanced, X_test_balanced, y_train_balanced, y_val_balanced, y_test_balanced = preprocessor.get_train_val_test_data()\n",
    "\n",
    "# set labels to integer 0 to 4 from 1 to 5\n",
    "y_train_balanced = [int(label-1) for label in y_train_balanced]\n",
    "y_val_balanced = [int(label-1) for label in y_val_balanced]\n",
    "y_test_balanced = [int(label-1) for label in y_test_balanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertModelBuilder(num_labels=5)\n",
    "model.train(X_train_balanced, y_train_balanced, X_val_balanced, y_val_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestione dei dati non bilanciati per confronto\n",
    "unbalanced_data = DataPreprocessor('unbalanced_test_data.csv')\n",
    "unbalanced_data.load_and_preprocess()\n",
    "unbalanced_data.split_data()\n",
    "# L'oversampling viene applicato solo ai dati di training per evitare bias\n",
    "X_train_unbalanced, X_val_unbalanced, X_test_unbalanced, y_train_unbalanced, y_val_unbalanced, y_test_unbalanced = unbalanced_data.get_train_val_test_data()\n",
    "\n",
    "# set labels to integer 0 to 4 from 1 to 5\n",
    "y_train_unbalanced = [int(label-1) for label in y_train_unbalanced]\n",
    "y_val_unbalanced = [int(label-1) for label in y_val_unbalanced]\n",
    "y_test_unbalanced = [int(label-1) for label in y_test_unbalanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valutazione su dati non bilanciati\n",
    "model.evaluate(X_test_unbalanced, y_test_unbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creazione e visualizzazione della matrice di confusione\n",
    "plot_confusion_matrix(model.get_model(), X_test_unbalanced, y_test_unbalanced, 'DistilBert') # TODO: fix"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
